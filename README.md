# JD_CV_AI_Solution

Using AI to extract, compare CV across JDs - An intelligent system for CV-Job Description matching and analysis.

## ğŸ¯ Overview

This project allows users to:
- Upload a CV (PDF) and parse it into structured JSON
- Paste a Job Description (JD) and parse it into structured JSON
- Compare the CV against the JD and generate:
  - ATS alignment score
  - Matched and missing skills
  - Gap analysis and recommendations

The project uses Ollama LLM locally (qwen3-latest) for parsing and comparison, with a Streamlit web interface for easy user interaction.

## ğŸš€ Features

- **PDF CV Processing**: Automatically extract and parse CV content from PDF files
- **Job Description Analysis**: Parse job requirements, skills, and qualifications
- **AI-Powered Matching**: Compare CVs against job descriptions using local LLM
- **ATS Score Calculation**: Generate applicant tracking system alignment scores
- **Skills Gap Analysis**: Identify missing skills and provide improvement recommendations
- **Interactive Web Interface**: User-friendly Streamlit application
- **Local Processing**: All data processing happens locally using Ollama

## ğŸ“ Folder Structure

```
CV_Agent/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ CV_2025.pdf
â”‚   â”œâ”€â”€ jd_sample.txt
â”‚   â”œâ”€â”€ cv_test.json
â”‚   â””â”€â”€ jd_test.json
â”‚
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ 1. PDF_ingestion.ipynb
â”‚   â”œâ”€â”€ 2. JD_CV_LLM_Parsing.ipynb
â”‚   â””â”€â”€ 3. CV_JD_Engine.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ document_ingestion/
â”‚   â”‚   â””â”€â”€ pdf_processor.py
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”œâ”€â”€ cv_parsers.py
â”‚   â”‚   â”œâ”€â”€ jd_parsers.py
â”‚   â”‚   â””â”€â”€ cv_vs_jd_parsers.py
â”‚   â”œâ”€â”€ utils_functions.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ prompt_templates/
â”‚       â”œâ”€â”€ cv_vs_jd_prompt.txt
â”‚       â”œâ”€â”€ cv_prompt.txt
â”‚       â””â”€â”€ jd_prompt.txt
â”‚
â”œâ”€â”€ main.py                  # Script used for testing
â”œâ”€â”€ app.py                   # Main streamlit app POC
â”œâ”€â”€ requirements_app.txt     # Minimal Python dependencies
â”œâ”€â”€ requirements.txt         # Full dependencies including notebooks
â””â”€â”€ README.md                # Project documentation
```

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.11 or higher
- [Ollama](https://ollama.ai/) installed and running
- qwen3-latest model downloaded via Ollama

### Step 1: Install Ollama

```bash
# On macOS
brew install ollama

# On Linux
curl -fsSL https://ollama.ai/install.sh | sh

# On Windows
# Download from https://ollama.ai/download
```

### Step 2: Pull the Required Model

```bash
ollama pull qwen3:latest
```

### Step 3: Clone the Repository

```bash
git clone https://github.com/dannyyqyq/JD_CV_AI_Solution.git
cd JD_CV_AI_Solution
```

### Step 4: Install Python Dependencies

```bash
# For running the Streamlit app only
pip install -r requirements_app.txt

# For full development including notebooks
pip install -r requirements.txt
```

## ğŸš€ Usage

### Running the Streamlit Application

1. Start Ollama service:
```bash
ollama serve
```

2. Run the Streamlit app:
```bash
streamlit run app.py
```

3. Open your browser to `http://localhost:8501`

### Using the Web Interface

1. **Upload CV**: Upload your PDF resume
2. **Paste Job Description**: Copy and paste the job description you're interested in
3. **Analyze**: Click to process and compare
4. **Review Results**: Get your ATS score, matched skills, and improvement recommendations

### Command Line Usage

For testing and development:

```bash
python main.py
```

## ğŸ““ Development Notebooks

The `notebook/` directory contains Jupyter notebooks for experimentation and development:

1. **PDF_ingestion.ipynb**: Experiments with PDF processing and text extraction
2. **JD_CV_LLM_Parsing.ipynb**: Development of LLM prompts and parsing logic
3. **CV_JD_Engine.ipynb**: Core comparison and scoring algorithm development

## ğŸ”§ Configuration

### Ollama Model Configuration

The system is configured to use `qwen3:latest`. To use a different model, update the model name in:
- `src/parsers/cv_parsers.py`
- `src/parsers/jd_parsers.py`
- `src/parsers/cv_vs_jd_parsers.py`

### Prompt Templates

Customize the AI behavior by editing prompt templates in `src/prompt_templates/`:
- `cv_prompt.txt`: Controls how CVs are parsed
- `jd_prompt.txt`: Controls how job descriptions are analyzed
- `cv_vs_jd_prompt.txt`: Controls the comparison and scoring logic

## ğŸ“Š Output Format

The system generates structured JSON outputs:

### CV Parsing Output
```json
{
  "personal_info": {...},
  "skills": [...],
  "experience": [...],
  "education": [...],
  "certifications": [...]
}
```

### Job Description Output
```json
{
  "requirements": [...],
  "skills_required": [...],
  "experience_level": "...",
  "qualifications": [...]
}
```

### Comparison Results
```json
{
  "ats_score": /10,
  "matched_skills": [...],
  "missing_skills": [...],
  "recommendations": [...],
  "gap_analysis": {...}
}
```
## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ› Troubleshooting

### Common Issues

**Ollama Connection Error**
- Ensure Ollama is running: `ollama serve`
- Open Ollama application running in backround
- Check if the model is installed: `ollama list`
  - If `qwen3:latest` is not within list, please do a `ollama pull qwen3:latest`
- Verify the model name matches in your configuration

**PDF Processing Issues**
- Ensure the PDF is text-based (not scanned images)

**Streamlit Not Starting**
- Verify all dependencies are installed
- Check Python version compatibility
- Ensure port 8501 is available

## ğŸ”® Future Enhancements

- [ ] Support for multiple CV formats (Word, HTML)
- [ ] Batch processing capabilities
- [ ] Advanced visualization dashboards
- [ ] Integration with job boards APIs
- [ ] Resume optimization suggestions
- [ ] Multi-language support
- [ ] Docker containerization
- [ ] OpenAI APIS severless deployment

---

â­ Feel free to play around!
